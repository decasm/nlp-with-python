{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from collections import Counter\n",
    "\n",
    "try:\n",
    "    directory = sys.args[1]\n",
    "except:\n",
    "    directory = '../review_json/'\n",
    "\n",
    "def load_reviews(directory):\n",
    "    file_names = os.listdir(directory)\n",
    "    reviews = [json.loads(open(directory+fn, 'r').read()) for fn in file_names]\n",
    "    reviews.sort(key=lambda r:len(r['text'])) # sort by length of review\n",
    "    reviews = reviews[5:] # get rid of 5 shortest reviews\n",
    "    for r in reviews:\n",
    "        r.pop('by') # remove 'by' field in each review\n",
    "    return reviews\n",
    "\n",
    "reviews = load_reviews(directory)\n",
    "reviews.sort(key=lambda r:r['release_year']) # sort by release_year\n",
    "titles = {r['title']:r for r in reviews} # dict of reviews by title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####\n",
    "\n",
    "# Corpus level analysis with set of reviews\n",
    "# let's remember what we're working with:\n",
    "len(reviews) # 7734 star-rated reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews.sort(key=lambda x:len(x['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews[0] # shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews[-1] # longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "NP: {<JJ>*<NNS?>+}\n",
    "    {<NNPS?>+}\n",
    "\"\"\"\n",
    "chunk_parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "# parse reviews and store results in review object\n",
    "def parse_review(r, parser):\n",
    "    try:\n",
    "        print(r['title'])\n",
    "        r['sentences'] = nltk.sent_tokenize(r['text'])\n",
    "        r['tokens'] = nltk.word_tokenize(r['text'])\n",
    "        r['pos_tags'] = nltk.pos_tag(r['tokens'])\n",
    "        text_wrapper = nltk.Text(r['tokens'])\n",
    "        text_wrapper.collocations(50) # prints collocations\n",
    "        r['collocations'] = text_wrapper._collocations\n",
    "        r['noun_chunks'] = [\n",
    "            str(c) for c in parser.parse(r['pos_tags'])\n",
    "            if type(c)==nltk.tree.Tree\n",
    "        ]\n",
    "        print(len(r['noun_chunks']))\n",
    "        print('')\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# could use a subset of reviews:\n",
    "westerns = [r for r in reviews if r['genres'] and 'Western' in r['genres']]\n",
    "for r in westerns:\n",
    "    parse_review(r, chunk_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_collos = []\n",
    "for r in westerns:\n",
    "    all_collos.extend(r['collocations'])\n",
    "\n",
    "Counter(all_collos).most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# westerns related to John Wayne\n",
    "for r in westerns:\n",
    "    if ('John', 'Wayne') in r['collocations']:\n",
    "        print(r['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# westerns with bad guys\n",
    "for r in westerns:\n",
    "    if ('bad', 'guys') in r['collocations']:\n",
    "        print(r['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# can generate tags by looking at common vocab not in stopwords list!\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n",
    "\n",
    "for tok in mr_tokens:\n",
    "     ...:     if tok.lower() not in stopwords.words('english') and tok.isalpha():\n",
    "     ...:         print(tok)\n",
    "\"\"\"\n",
    "\n",
    "# let's join the Ebert corpus into a single block of text\n",
    "reviews.sort(key=lambda x:x['date_published'])\n",
    "review_texts = [r['text'] for r in reviews]\n",
    "all_text = '\\n\\n\\n\\n'.join(review_texts)\n",
    "\n",
    "# demonstrate stemming on \"fall\"?\n",
    "all_text.count('fell in love') # the limitation of stemming! fell !> fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text.count('falling in love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text.count('fall in love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text.count('falls in love')\n",
    "# all_text.count('fall out of love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need to tokenize to go deeper\n",
    "all_tokens = nltk.word_tokenize(all_text) # this will take a moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's find all _falling in love_ phrases with a stemmer\n",
    "stemmer = PorterStemmer()\n",
    "romances = []\n",
    "trigrams = nltk.ngrams(all_tokens, n=3)\n",
    "for tri in trigrams:\n",
    "    if ' '.join([stemmer.stem(tri[0]),tri[1],tri[2]]) == 'fall in love':\n",
    "        print(tri)\n",
    "        romances.append(tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(romances) # 862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token frequencies: tf-idf\n",
    "# formula may differ--could log some of these values\n",
    "# also n+1 for some of these values?\n",
    "all_tokens_count = len(all_tokens)\n",
    "all_counts = Counter(all_tokens)\n",
    "all_freqs = {tok:all_counts[tok]/all_tokens_count for tok in all_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mr = titles['Minority Report (2002)']\n",
    "mr_tokens = nltk.word_tokenize(mr['text'])\n",
    "mr_token_count = len(mr_tokens)\n",
    "mr_counts = Counter(mr_tokens)\n",
    "mr_counts.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mr_freqs = {tok:mr_counts[tok]/mr_token_count for tok in mr_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf_scores = [(tok, mr_freqs[tok]/all_freqs[tok]) for tok in set(mr_tokens)]\n",
    "tf_idf_scores.sort(key=lambda s:s[1], reverse=True)\n",
    "tf_idf_scores # most to least uniquely characteristic tokens of Minority Report\n",
    "# consider how to extend this to other reviews across the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's use the nltk.Text wrapper to explore the whole corpus more\n",
    "all_wrapper = nltk.Text(all_tokens)\n",
    "all_fdist = nltk.FreqDist(all_wrapper) # unique tokens with their frequencies\n",
    "all_fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'aphrodisiac' in all_fdist # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_fdist['aphrodisiac'] # 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# actors\n",
    "# Freeman, Poitier, Gooding, Glover, Snipes\n",
    "# consider comparison of female actors / actresses\n",
    "all_wrapper.dispersion_plot(\n",
    "    ['Eastwood','Brando','Niro','Schwarzenegger','Hanks','Depp',\n",
    "    'Pitt','Spacey','DiCaprio','Clooney','Osment','Gosling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_wrapper.concordance('laugh', lines=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_wrapper.concordance('cry', lines=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_wrapper.concordance('fight', lines=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes a moment to do the first one\n",
    "all_wrapper.similar('scene') # noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_wrapper.similar('actor') # noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_wrapper.similar('woman') # noun\n",
    "all_wrapper.similar('pleasant') # adjective\n",
    "all_wrapper.similar('hideous') # adjective\n",
    "all_wrapper.similar('entertaining') # adjective\n",
    "all_wrapper.similar('foreign') # adjective\n",
    "all_wrapper.similar('intimately') # adverb\n",
    "all_wrapper.similar('slay') # verb\n",
    "all_wrapper.similar('pray') # verb\n",
    "\n",
    "all_wrapper.common_contexts(['good','bad'])\n",
    "all_wrapper.common_contexts(['good','evil'])\n",
    "all_wrapper.common_contexts(['man','woman'])\n",
    "all_wrapper.common_contexts(['boy','girl'])\n",
    "all_wrapper.common_contexts(['little','small'])\n",
    "all_wrapper.common_contexts(['big','huge'])\n",
    "all_wrapper.common_contexts(['short','long'])\n",
    "all_wrapper.common_contexts(['true','false'])\n",
    "all_wrapper.common_contexts(['very','extremely'])\n",
    "all_wrapper.common_contexts(['emotion','feeling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualizing our data\n",
    "import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# date_published (histogram)\n",
    "pub_dates = [int(r['date_published'].split('-')[0]) for r in reviews] # year\n",
    "pub_date_range = max(pub_dates)+1 - min(pub_dates)\n",
    "pyplot.hist(pub_dates, bins=pub_date_range)\n",
    "pyplot.show() # early outlier in 1960\n",
    "reviews[0] # mistake--Le Petit Soldat (1960) was clearly not reviewed in 1960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# release_year (histogram)\n",
    "release_dates = [r['release_year'] for r in reviews]\n",
    "release_date_range = max(release_dates)+1 - min(release_dates)\n",
    "pyplot.hist(release_dates, bins=pub_date_range)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# character count of text (histogram)\n",
    "char_counts = [len(r['text']) for r in reviews]\n",
    "char_counts_range = max(char_counts)+1 - min(char_counts)\n",
    "pyplot.hist(char_counts, bins=int(char_counts_range/10))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word count of text (histogram())\n",
    "review_tokens = [nltk.word_tokenize(r['text']) for r in reviews]\n",
    "review_words = [[tok for tok in tokens if tok.isalpha()] for tokens in review_tokens]\n",
    "word_counts = [len(words) for words in review_words]\n",
    "word_count_range = max(word_counts)+1 - min(word_counts)\n",
    "pyplot.hist(word_counts, bins=int(word_count_range/10))\n",
    "pyplot.show() # bimodal distribution--indicates varying formats\n",
    "# did Ebert work under 1000-word and 1500-word limits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# genre (pie chart)\n",
    "genre_instances = [inst for r in reviews if r['genres'] for inst in r['genres']]\n",
    "#from collections import Counter\n",
    "genre_counts = Counter(genre_instances)\n",
    "genre_counts\n",
    "#genres, counts = zip(*sorted(genre_counts.items()))\n",
    "genres, counts = zip(*sorted([gc for gc in genre_counts.items() if gc[1]>50], key=lambda gc:gc[1]))\n",
    "pyplot.pie(counts, labels=genres)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# running_time (histogram)\n",
    "running_times = [r['running_time']/60 for r in reviews if r['running_time']]\n",
    "running_times_range = max(running_times)+1 - min(running_times)\n",
    "pyplot.hist(running_times, bins=int(running_times_range*20))\n",
    "pyplot.show() # mass is between 1 and 2.5 hours with long tail to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mpaa_rating (pie chart)\n",
    "# from collections import Counter\n",
    "mpaa_ratings = [r['mpaa_rating'] for r in reviews if r['mpaa_rating']]\n",
    "rating_counts = Counter(mpaa_ratings)\n",
    "rating_counts\n",
    "ratings, counts = zip(*sorted([r for r in rating_counts.items() if r[1]>10], key=lambda r:r[1]))\n",
    "pyplot.pie(counts, labels=ratings)\n",
    "pyplot.show() # vast minority R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# star_rating (hist)\n",
    "star_ratings = [r['star_rating'] for r in reviews]\n",
    "Counter(star_ratings)\n",
    "#star_range = max(star_ratings)+1 - min(star_ratings)\n",
    "pyplot.hist(star_ratings, bins=8)\n",
    "pyplot.show() # displays funny--how to fix?\n",
    "# note the dip in 2.5 star ratings--a sign of irrationality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEXT: let's brainstorm some of operations over the whole corpus!\n",
    "\n",
    "\n",
    "# means and medians:\n",
    "# stars on mpaa_rating\n",
    "# stars on genre\n",
    "\n",
    "# regression:\n",
    "# http://stackoverflow.com/questions/3949226/calculating-pearson-correlation-and-significance-in-python\n",
    "# stars on release year post 1967\n",
    "# stars on review year\n",
    "# stars on review length\n",
    "# stars on running_time\n",
    "\n",
    "# OPTIONAL: DOCUMENT CLASSIFICATION\n",
    "# http://www.nltk.org/book/ch06.html#document-classification\n",
    "# train on mpaa ratng and star rating"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
